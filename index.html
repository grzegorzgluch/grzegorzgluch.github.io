<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
    <meta name="description" content="" />
    <meta name="author" content="" />
    <title>GG</title>
    <link rel="icon" type="image/x-icon" href="dist/assets/img/favicon.ico" />

    <!-- Font Awesome icons (free version)-->
    <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>

    <!-- Google fonts-->
    <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
    <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />

    <!-- Core theme CSS (includes Bootstrap)-->
    <link href="dist/css/styles.css" rel="stylesheet" />

    <!-- Site tweaks -->
    <style>
      /* Global: slightly tighter vertical rhythm */
      .resume-section-content .lead { margin-bottom: 1.75rem; }
      .resume-section-content h2.mb-5 { margin-bottom: 2.25rem !important; }

      /* Talks */
      .talk-item h4 { letter-spacing: 0.4px; }
      .talk-item .small { font-size: 0.85rem; }
      .talk-item em { font-style: normal; color: #555; }

      /* Publications: tighter layout + stronger venues + subtler links */
      #publications .resume-item { margin-bottom: 1.25rem !important; } /* replaces mb-5 whitespace */
      #publications .resume-content h4 { margin-bottom: 0.25rem; }

      #publications .pub-venue {
        margin-top: 0.15rem;
        margin-bottom: 0.4rem;
      }

      /* Venue badges: prominent but compact */
      #publications .pub-venue .badge {
        font-weight: 800;
        letter-spacing: 0.35px;
        text-transform: uppercase;
        font-size: 0.78rem;
        padding: 0.42em 0.6em;
        margin-right: 0.35rem;
        margin-bottom: 0.25rem;
        border-radius: 999px;
      }

      /* Slightly different feel for status tags */
      #publications .pub-venue .badge.pub-status {
        font-weight: 700;
        opacity: 0.95;
      }

      #publications .pub-authors {
        color: rgba(0,0,0,0.65);
        margin-bottom: 0.35rem;
      }

      #publications .pub-links .btn {
        padding: 0.15rem 0.45rem;
        font-size: 0.78rem;
        opacity: 0.85;
      }
      #publications .pub-links .btn:hover { opacity: 1; }

      #publications details { margin-top: 0.35rem; }
      #publications details summary { cursor: pointer; }
      #publications details p { margin-top: 0.35rem; }
      #publications .subheading.mb-3 { margin-top: 2rem; }

      /* Button spacing in groups */
      .btn-group .btn:not(:last-child) { margin-right: 8px; }
    </style>
  </head>

  <body id="page-top">
    <!-- Navigation-->
    <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">
        <span class="d-block d-lg-none">GRZEGORZ G≈ÅUCH</span>
        <span class="d-none d-lg-block">
          <img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="dist/assets/img/profile.jpg" alt="..." />
        </span>
      </a>
      <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive"
              aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav">
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#talksandmedia">Talks and Media</a></li>
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#publications">Publications</a></li>
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#teaching">Teaching</a></li>
          <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
        </ul>
      </div>
    </nav>

    <!-- Page Content-->
    <div class="container-fluid p-0">
      <!-- About-->
      <section class="resume-section" id="about">
        <div class="resume-section-content">
          <h1 class="mb-0" style="font-size: 45px;">
            Grzegorz (Greg)
            <span class="text-primary">G≈Çuch</span>
          </h1>
          <div class="subheading mb-5" style="font-size: 18px;">
            Simons Institute for the Theory of Computing, Melvin Calvin Laboratory, Room 318 ¬∑ Berkeley ¬∑ CA 94720
          </div>

          <p class="lead mb-5">
            I am a <a href="https://simons.berkeley.edu/people/postdoctoral-researchers" target="_blank">Simons-Berkeley Postdoctoral Researcher</a>
            hosted by <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/goldwasser.html" target="_blank">Shafi Goldwasser</a> currently at MIT.
            I completed my PhD at EPFL, where I was advised by a duo:
            <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a> and
            <a href="https://theory.epfl.ch/kapralov/" target="_blank">Michael Kapralov</a>.
            Before that I studied at University of Wroclaw working with
            <a href="https://ii.uni.wroc.pl/~jma/index.phtml" target="_blank">Jerzy Marcinkowski</a>.
          </p>

          <p class="lead mb-5">
            I work on the theoretical aspects of AI, focusing on AI safety and resilience. I am a member of the
            <a href="https://simons.berkeley.edu/research-pods/resilience-research-pod" target="_blank">Resilience Research Pod at Simons</a>.
            My research interests also include quantum complexity theory and its connections to physics.
          </p>

          <p class="lead mb-5">Trying to make an impact.</p>
          <p class="lead mb-5">Contact: grzegorzgluch93@gmail.com</p>

          <div class="social-icons">
            <a href="https://scholar.google.com/citations?user=gg2sjRIAAAAJ&hl=en" target="_blank">
              <img src="dist/assets/img/google2.png" alt="Google Scholar" style="width:70px;height:70px;">
            </a>
          </div>
        </div>
      </section>
      <hr class="m-0" />

      <!-- Talks and Media -->
      <section class="resume-section" id="talksandmedia">
        <div class="resume-section-content">
          <h2 class="mb-5">Talks and Media</h2>

          <!-- Media -->
          <div class="talk-item mb-5">
            <div class="text-muted mb-1">Dec 10, 2025</div>
            <h4 class="mb-2">Quanta Magazine</h4>
            <p class="mb-2">
              <em>‚ÄúOn the Impossibility of Separating Intelligence from Judgment:
              The Computational Intractability of Filtering for AI Alignment‚Äù</em>
              was featured in a Quanta Magazine article.
            </p>
            <a href="https://www.quantamagazine.org/cryptographers-show-that-ai-protections-will-always-have-holes-20251210/"
               target="_blank" class="btn btn-secondary btn-sm" role="button" aria-pressed="true">
              Read the article
            </a>
          </div>

          <hr class="my-4" />

          <!-- Talks -->
          <div class="talk-item mb-4">
            <div class="text-muted mb-1">London ¬∑ Oct 30, 2025</div>
            <h4 class="mb-0"><strong>UK AISI Alignment Conference</strong></h4>
            <div class="text-muted small mb-1">Invited talk</div>
            <p class="mb-0"><em>Reasoning Provably Improves Safety for Generation</em></p>
          </div>

          <div class="talk-item mb-4">
            <div class="text-muted mb-1">Oct 21, 2025</div>
            <h4 class="mb-0"><strong>New York University</strong></h4>
            <div class="text-muted small mb-1">Crypto and Security Seminar</div>
            <p class="mb-0"><em>What Can Cryptography Tell Us About AI Safety?</em></p>
          </div>

          <div class="talk-item mb-2">
            <div class="text-muted mb-1">Oct 14, 2025</div>
            <h4 class="mb-0"><strong>Massachusetts Institute of Technology</strong></h4>
            <div class="text-muted small mb-1">ML + Crypto Seminar</div>
            <p class="mb-0"><em>What Can Cryptography Tell Us About AI Safety?</em></p>
          </div>
        </div>
      </section>
      <hr class="m-0" />

      <!-- Publications-->
      <section class="resume-section" id="publications">
        <div class="resume-section-content">
          <h2 class="mb-5">Publications</h2>
          <p class="lead mb-5">Authors appear in alphabetical order (a convention in theoretical computer science).</p>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2504.20310" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Private Proofs of When and Where</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-secondary pub-status">Preprint</span>
              </div>
              <div class="pub-authors">
                with <a href="https://www.cs.columbia.edu/~ug2150/" target="_blank">Uma Girish</a>,
                <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/goldwasser.html" target="_blank">Shafi Goldwasser</a>,
                <a href="https://www.cs.columbia.edu/~tal/" target="_blank">Tal Malkin</a>,
                <a href="https://scholar.google.com/citations?user=zd6quKkAAAAJ&hl=en" target="_blank">Leo Orshansky</a>,
                <a href="https://www.henryyuen.net/" target="_blank">Henry Yuen</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/2504.20310" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  Position verification schemes are interactive protocols where entities prove their physical location to others; this enables interactive proofs for statements of the form "I am at a location L."
                  Although secure position verification cannot be achieved with classical protocols (even with computational assumptions), they are feasible with quantum protocols.
                  In this paper we introduce the notion of zero-knowledge position verification, which generalizes position verification in two ways:
                  1. enabling entities to prove more sophisticated statements about their locations at different times (for example, "I was NOT near location L at noon yesterday").
                  2. maintaining privacy for any other detail about their true location besides the statement they are proving.
                  We construct zero-knowledge position verification from standard position verification and post-quantum one-way functions. The central tool in our construction is a primitive we call position commitments,
                  which allow entities to privately commit to their physical position in a particular moment, which is then revealed at some later time.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2504.20310" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">A Cryptographic Perspective on Mitigation vs. Detection in Machine Learning</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-secondary pub-status">Preprint</span>
              </div>
              <div class="pub-authors">
                with <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/goldwasser.html" target="_blank">Shafi Goldwasser</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/2504.20310" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  In this paper, we initiate a cryptographically inspired theoretical study of detection versus mitigation of adversarial inputs produced by attackers of Machine Learning algorithms during inference time.
                  We formally define defense by detection (DbD) and defense by mitigation (DbM). Our definitions come in the form of a 3-round protocol between two resource-bounded parties: a trainer/defender and an attacker.
                  The attacker aims to produce inference-time inputs that fool the training algorithm. We define correctness, completeness, and soundness properties to capture successful defense at inference time while not degrading
                  (too much) the performance of the algorithm on inputs from the training distribution.
                  We first show that achieving DbD and achieving DbM are equivalent for ML classification tasks. Surprisingly, this is not the case for ML generative learning tasks, where there are many possible correct outputs
                  that can be generated for each input. We show a separation between DbD and DbM by exhibiting a generative learning task for which is possible to defend by mitigation but is provably impossible to defend by detection
                  under the assumption that the Identity-Based Fully Homomorphic Encryption (IB-FHE), publicly-verifiable zero-knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARK) and Strongly Unforgeable Signatures exist.
                  The mitigation phase uses significantly fewer samples than the initial training algorithm.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2507.07341" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">On the Impossibility of Separating Intelligence from Judgment: The Computational Intractability of Filtering for AI Alignment</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">ICLR 2026</span>
              </div>
              <div class="pub-authors">
                with <a href="https://zuseschoolrelai.de/people/scientists/sarah-ball/" target="_blank">Sarah Ball</a>,
                <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/goldwasser.html" target="_blank">Shafi Goldwasser</a>,
                <a href="https://jpsm.umd.edu/facultyprofile/kreuter/frauke" target="_blank">Frauke Kreuter</a>,
                <a href="https://omereingold.wordpress.com/" target="_blank">Omer Reingold</a>,
                <a href="https://guyrothblum.wordpress.com/" target="_blank">Guy N. Rothblum</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/2507.07341" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  With the increased deployment of large language models (LLMs), one concern is their potential misuse for generating harmful content.
                  Our work studies the alignment challenge, with a focus on filters to prevent the generation of unsafe information. Two natural points of intervention
                  are the filtering of the input prompt before it reaches the model, and filtering the output after generation. Our main results demonstrate computational
                  challenges in filtering both prompts and outputs. First, we show that there exist LLMs for which there are no efficient prompt filters: adversarial prompts
                  that elicit harmful behavior can be easily constructed, which are computationally indistinguishable from benign prompts for any efficient filter.
                  Our second main result identifies a natural setting in which output filtering is computationally intractable. All of our separation results are under
                  cryptographic hardness assumptions. In addition to these core findings, we also formalize and study relaxed mitigation approaches, demonstrating further
                  computational barriers. We conclude that safety cannot be achieved by designing filters external to the LLM internals (architecture and weights); in particular,
                  black-box access to the LLM will not suffice. Based on our technical results, we argue that an aligned AI system's intelligence cannot be separated from its judgment.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2410.08864" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">The Good, the Bad and the Ugly: Watermarks, Transferable Attacks and Adversarial Defenses</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">NeurIPS 2025</span>
                <span class="badge bg-secondary">ICML 2024 Workshop</span>
              </div>
              <div class="pub-authors">
                with <a href="https://b-turan.github.io/" target="_blank">Berkant Turan</a>,
                <a href="https://sites.google.com/view/sgnagarajan/home" target="_blank">Sai Ganesh Nagarajan</a>,
                <a href="https://www.pokutta.com/" target="_blank">Sebastian Pokutta</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/2410.08864" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  We formalize and analyze the trade-off between backdoor-based watermarks and adversarial defenses, framing it as an interactive protocol between a verifier and a prover.
                  While previous works have primarily focused on this trade-off, our analysis extends it by identifying transferable attacks as a third, counterintuitive but necessary option.
                  Our main result shows that for all learning tasks, at least one of the three exists: a watermark, an adversarial defense, or a transferable attack.
                  By transferable attack, we refer to an efficient algorithm that generates queries indistinguishable from the data distribution and capable of fooling all efficient defenders.
                  Using cryptographic techniques, specifically fully homomorphic encryption, we construct a transferable attack and prove its necessity in this trade-off.
                  Furthermore, we show that any task that satisfies our notion of a transferable attack implies a cryptographic primitive, thus requiring the underlying task to be computationally complex.
                  Finally, we show that tasks of bounded VC-dimension allow adversarial defenses against all attackers, while a subclass allows watermarks secure against fast adversaries.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2303.02080" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Nonlocality under Computational Assumptions</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">STOC 2024</span>
                <span class="badge bg-secondary">QIP 2025</span>
              </div>
              <div class="pub-authors">
                with <a href="https://lasec.epfl.ch/people/barooti/" target="_blank">Khashayar Barooti</a>,
                <a href="https://agheorghiu.com/" target="_blank">Alexandru Gheorghiu</a>,
                <a href="https://scholar.google.com/citations?user=u-DfxLcAAAAJ&hl=fr" target="_blank">Marc-Olivier Renou</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://dl.acm.org/doi/abs/10.1145/3618260.3649750" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/2303.02080" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  Nonlocality and its connections to entanglement are fundamental features of quantum mechanics that have found numerous applications in quantum information science.
                  A set of correlations is said to be nonlocal if it cannot be reproduced by spacelike-separated parties sharing randomness and performing local operations.
                  An important practical consideration is that the runtime of the parties has to be shorter than the time it takes light to travel between them.
                  One way to model this restriction is to assume that the parties are computationally bounded. We therefore initiate the study of nonlocality under computational assumptions and derive the following results:
                  (a) We define the set ùñ≠ùñæùñ´ (not-efficiently-local) as consisting of all bipartite states whose correlations arising from local measurements cannot be reproduced with shared randomness and polynomial-time local operations.
                  (b) Under the assumption that the Learning With Errors problem cannot be solved in quantum polynomial-time, we show that ùñ≠ùñæùñ´=ùñ§ùñ≠ùñ≥, where ùñ§ùñ≠ùñ≥ is the set of all bipartite entangled states (pure and mixed).
                  This is in contrast to the standard notion of nonlocality where it is known that some entangled states, e.g. Werner states, are local.
                  (c) We prove that if ùñ≠ùñæùñ´=ùñ§ùñ≠ùñ≥ unconditionally, then ùô±ùöÄùôø‚â†ùôøùôø.
                  (d) Using (c), we show that a certain natural class of 1-round delegated quantum computation protocols that are sound against ùôøùôø provers cannot exist.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2303.07874" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Bayes Complexity of Learners vs Overfitting</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-secondary pub-status">Under Review</span>
              </div>
              <div class="pub-authors">
                with <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/2303.07874" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  We introduce a new notion of complexity of functions and we show that it has the following properties: (i) it governs a PAC Bayes-like generalization bound,
                  (ii) for neural networks it relates to natural notions of complexity of functions (such as the variation), and (iii) it explains the generalization gap between
                  neural networks and linear schemes. Moreover, our notion naturally generalizes to neural networks with several layers. Even though the computation of our complexity
                  is nontrivial in general, an upper-bound is often easy to derive, even for higher number of layers and functions with structure, such as period functions.
                  An upper-bound we derive allows to show a separation in the number of samples needed for good generalization between 2 and 4-layer neural networks for periodic functions.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://proceedings.mlr.press/v206/gluch23a.html" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Breaking a Classical Barrier for Classifying Arbitrary Test Examples in the Quantum Model</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">AISTATS 2023</span>
                <span class="badge bg-secondary">QIP 2022 Poster</span>
              </div>
              <div class="pub-authors">
                with <a href="https://lasec.epfl.ch/people/barooti/" target="_blank">Khashayar Barooti</a>,
                <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://proceedings.mlr.press/v206/gluch23a.html" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/2112.09625" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Informal Abstract</summary>
                <p class="mb-0">
                  This paper presents a surprising connection between recent advances in delegation of quantum computation to adversarial robustness.
                  Imagine an adversary A that is in between a classifier C and a source S producing samples to be classified.
                  Can we design an interactive protocol between C and the A, in which A would convince C that the samples being sent for classification really came from S?
                  Using ideas from delegation of quantum computation we show it is possible to do it if A receives quantum states from S and A communicates with C classically.
                  Why do we need quantum mechanics? Assume that S is uniform on {0,1}^n. How can A convince C that the samples he sent really came from S and were not handcrafted
                  by S (if A received classical samples from S)? This seems to us be an almost impossible problem to solve, as we discuss in the paper.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/2104.05508" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Noether: The more things change, the more stay the same</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-secondary pub-status">Under Review</span>
              </div>
              <div class="pub-authors">
                with <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/2104.05508" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Informal Abstract</summary>
                <p class="mb-0">
                  The field of theoretical machine learning managed to produce some initial explanations for why neural networks perform so well in practice.
                  Unfortunately when reading these papers it is hard to see a common theme or a unifying message.
                  In this paper we show how to look at many of the recent advances through one lens, i.e. the lens of symmetries.
                  We show how this concept explains many previous results and how it helps to obtain new ones. To do all of that we study a connection to Noether's theorem from physics.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://proceedings.neurips.cc/paper/2021/hash/ae06fbdc519bddaa88aa1b24bace4500-Abstract.html" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Exponential Separation between Two Learning Models and Adversarial Robustness</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">NeurIPS 2021</span>
                <span class="badge bg-secondary">Spotlight</span>
              </div>
              <div class="pub-authors">
                with <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://proceedings.neurips.cc/paper/2021/hash/ae06fbdc519bddaa88aa1b24bace4500-Abstract.html" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/2102.05475" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Informal Abstract</summary>
                <p class="mb-0">
                  There are two sides of this paper. The technical one and potential applications to adversarial robustness.
                  On the technical side we show exponential separation between two models: the standard PAC-learning model and an Equivalence-Query model.
                  Thinking of adversarial examples as counterexamples, our result can be viewed as theoretical confirmation of findings that structured adversarial examples
                  can speed up learning. We also discuss implications for adversarial robustness beyond norm-bounded threat models.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="http://proceedings.mlr.press/v139/gluch21a.html" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Query Complexity of Adversarial Attacks</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">ICML 2021</span>
              </div>
              <div class="pub-authors">
                with <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="http://proceedings.mlr.press/v139/gluch21a.html" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/2010.01039" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Informal Abstract</summary>
                <p class="mb-0">
                  How hard is it to adversarially attack a network with only black-box access?
                  We analyze a spectrum of threat models indexed by query access and give lower bounds on the number of queries needed to match white-box attacks,
                  in terms of entropy of decision boundaries. We also analyze classical learning algorithms on synthetic tasks and prove meaningful security guarantees.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611976465.97" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Spectral Clustering Oracles in Sublinear Time</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">SODA 2021</span>
              </div>
              <div class="pub-authors">
                with <a href="https://theory.epfl.ch/kapralov/" target="_blank">Michael Kapralov</a>,
                <a href="https://sites.google.com/site/silviolattanzi/" target="_blank">Silvio Lattanzi</a>,
                Aida Mousavifar,
                <a href="https://ls2-www.cs.tu-dortmund.de/grav/en/grav_files/people/sohler" target="_blank">Christian Sohler</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://epubs.siam.org/doi/abs/10.1137/1.9781611976465.97" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/2101.05549" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  Given a graph G that can be partitioned into k disjoint expanders, we construct a small-space data structure (a spectral clustering oracle)
                  that allows quickly classifying vertices according to their cluster. Our main result gives sublinear query time with strong per-cluster guarantees,
                  using dot-product access to a spectral embedding via estimates of short random walks and a carefully analyzed linear transformation.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="http://proceedings.mlr.press/v108/gluch20a.html" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Constructing a provably adversarially-robust classifier from a high accuracy one</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">AISTATS 2020</span>
              </div>
              <div class="pub-authors">
                with <a href="https://people.epfl.ch/rudiger.urbanke" target="_blank">Rudiger Urbanke</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="http://proceedings.mlr.press/v108/gluch20a.html" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/1912.07561" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  Given black-box access to a high-accuracy classifier f, we show how to construct a classifier g that remains accurate and is provably robust to adversarial L2 perturbations.
                  Our approach builds on randomized smoothing and uses geometric tools like random partitions and doubling dimension to bound adversarial error in terms of optimal error.
                </p>
              </details>
            </div>
          </div>

          <div class="subheading mb-3">Pre-PhD work</div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://drops.dagstuhl.de/opus/volltexte/2019/10317/" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">The first order truth behind undecidability of regular path queries determinacy</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">ICDT 2019</span>
              </div>
              <div class="pub-authors">
                with <a href="https://ii.uni.wroc.pl/~jma/index.phtml" target="_blank">Jerzy Marcinkowski</a>,
                <a href="https://ii.uni.wroc.pl/instytut/pracownicy/103" target="_blank">Piotr Ostropolski-Nalewaja</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://drops.dagstuhl.de/opus/volltexte/2019/10317/" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/1808.07767" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  We show that determinacy remains undecidable even without regularity assumptions: it is undecidable for finite unions of conjunctive path queries,
                  strengthening prior undecidability results for Regular Path Queries.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://dl.acm.org/doi/abs/10.1145/3209108.3209120" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">Can One Escape Red Chains? Regular Path Queries Determinacy is Undecidable</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-primary">LICS 2018</span>
              </div>
              <div class="pub-authors">
                with <a href="https://ii.uni.wroc.pl/~jma/index.phtml" target="_blank">Jerzy Marcinkowski</a>,
                <a href="https://ii.uni.wroc.pl/instytut/pracownicy/103" target="_blank">Piotr Ostropolski-Nalewaja</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://dl.acm.org/doi/10.1145/3209108.3209120" target="_blank" class="btn btn-secondary" role="button">conference</a>
                <a href="https://arxiv.org/abs/1802.01554" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  We solve a long-standing open problem by proving that Query Determinacy is undecidable for Regular Path Queries, a foundational query language for graph databases.
                </p>
              </details>
            </div>
          </div>

          <!-- Publication -->
          <div class="resume-item d-flex flex-column flex-md-row justify-content-between">
            <div class="resume-content">
              <a href="https://arxiv.org/abs/1703.01475" target="_blank" style="text-decoration: none">
                <h4 class="mb-0">4/3 Rectangle Tiling lower bound</h4>
              </a>
              <div class="pub-venue">
                <span class="badge bg-secondary pub-status">Preprint</span>
              </div>
              <div class="pub-authors">
                with <a href="https://www.ii.uni.wroc.pl/~lorys/" target="_blank">Krzysztof Lory≈õ</a>
              </div>
              <div class="pub-links btn-group btn-group-sm" role="group" aria-label="paper links">
                <a href="https://arxiv.org/abs/1703.01475" target="_blank" class="btn btn-secondary" role="button">arXiv</a>
              </div>
              <details>
                <summary>Abstract</summary>
                <p class="mb-0">
                  Given an n√ón array of positive numbers, find a tiling using at most p rectangles minimizing the maximum rectangle weight (sum of covered entries).
                  We prove it is NP-hard to approximate this problem within a factor of 4/3.
                </p>
              </details>
            </div>
          </div>

        </div>
      </section>
      <hr class="m-0" />

      <!--Teaching-->
      <section class="resume-section" id="teaching">
        <div class="resume-section-content">
          <h2 class="mb-5">Teaching</h2>
          <h4 class="mb-0">
            Videos from a course on "Quantum Interactive Proofs" I held at EPFL can be found
            <a href="https://kashbrti.github.io/quantum-ip/" target="_blank" class="btn btn-secondary" role="button" aria-pressed="true">here</a>
          </h4>
        </div>
      </section>
      <hr class="m-0" />

      <!-- Education-->
      <section class="resume-section" id="education">
        <div class="resume-section-content">
          <h2 class="mb-5">Education</h2>

          <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
            <div class="flex-grow-1">
              <h3 class="mb-0">√âcole Polytechnique F√©d√©rale de Lausanne (<span style="font-weight: bold; color: #ff0000;">EPFL</span>)</h3>
              <div>Doctor of Philosophy</div>
              <div class="subheading mb-3">Computer Science</div>
            </div>
            <div class="flex-shrink-0"><span class="text-primary">2018 - 2024</span></div>
          </div>

          <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
            <div class="flex-grow-1">
              <h3 class="mb-0">University of Wroclaw</h3>
              <div>Master of Science</div>
              <div class="subheading mb-3">Computer Science</div>
              <ul>
                <li>MSc Research Scholar, working with <a href="https://ii.uni.wroc.pl/~jma/index.phtml" target="_blank">Jerzy Marcinkowski</a></li>
              </ul>
            </div>
            <div class="flex-shrink-0"><span class="text-primary">2015 - 2018</span></div>
          </div>

          <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
            <div class="flex-grow-1">
              <h3 class="mb-0">University of Wroclaw</h3>
              <div>Bachelor of Science</div>
              <div class="subheading mb-3">Mathematics</div>
            </div>
            <div class="flex-shrink-0"><span class="text-primary">2012 - 2015</span></div>
          </div>

          <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
            <div class="flex-grow-1">
              <h3 class="mb-0">University of Wroclaw</h3>
              <div>Bachelor of Science</div>
              <div class="subheading mb-3">Computer Science</div>
            </div>
            <div class="flex-shrink-0"><span class="text-primary">2012 - 2015</span></div>
          </div>
        </div>
      </section>
      <hr class="m-0" />
    </div>

    <!-- Bootstrap core JS-->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Core theme JS-->
    <script src="js/scripts.js"></script>
  </body>
</html>
